# Directory location where the crawled news articles and labels are stored
#
# Download Chrome driver and update the location path
# Link: https://sites.google.com/a/chromium.org/chromedriver/downloads

[GOOGLE_COLAB]
label_path = /content/drive/MyDrive/Colab Notebooks/data/mvp21/sentiments/labeled_sentences.xlsx
data_dir   = /content/drive/MyDrive/Colab Notebooks/data/mvp21/
sample_dir = /content/drive/MyDrive/Colab Notebooks/data/mvp21/samples/
model_path = /content/drive/MyDrive/Colab Notebooks/data/mvp21/model/saved_weights.pt
chrome_driver_path = /content/drive/MyDrive/Colab Notebooks/data/mvp21/chromedriver/chromedriver.exe

[DESKTOP-G4VC383]
label_path = D:\Personal\Koichi\DATA\mvp21\sentiments\labeled_sentences.xlsx
data_dir   = D:\Personal\Koichi\DATA\mvp21\
sample_dir = D:\Personal\Koichi\DATA\mvp21\samples\
model_path = D:\Personal\Koichi\DATA\mvp21\model\saved_weights.pt
chrome_driver_path = D:\Personal\Koichi\DATA\mvp21\chromedriver\chromedriver.exe

[N-1274]
label_path = \\DESKTOP-G4VC383\Koichi\DATA\mvp21\sentiments\labeled_sentences.xlsx
data_dir   = \\DESKTOP-G4VC383\Koichi\DATA\mvp21\
sample_dir = \\DESKTOP-G4VC383\Koichi\DATA\mvp21\samples\
model_path = \\DESKTOP-G4VC383\Koichi\DATA\mvp21\model\saved_weights.pt
chrome_driver_path = \\DESKTOP-G4VC383\Koichi\DATA\mvp21\chromedriver\chromedriver.exe

[dmz-saf-2.nlehd.de]
label_path = /media/data/kfunaya/mvp21/sentiments/labeled_sentences.xlsx
data_dir   = /media/data/kfunaya/mvp21/
sample_dir = /media/data/kfunaya/mvp21/samples/
model_path = /media/data/kfunaya/mvp21/model/saved_weights.pt
chrome_driver_path = /media/data/kfunaya/mvp21/chromedriver/chromedriver.exe

# Waiting time(sec) for Selenium to load the page completely 
[DELAY_VALUE]
delay = 10

# The news sources and their corresponding web pages to be crawled - 
# To add a new source, update the list below and add a corresponding 
# method to NewsExtractor with signature: METHOD( PAGE, FOLDER_NAME )
# [See NewsExtractor class for reference]
# NOTE: The new source and method name should be same and call 
# saveArticle( ARTICLE_LINK, FOLDER_NAME) to save an article
[NEWS_SOURCE]
nhk = https://www3.nhk.or.jp/news/catnew.html?utm_int=news_contents_news-main_more#!/4/
kyodo = https://www.kyodo.co.jp/
nikkei = https://www.nikkei.com/
jiji = https://www.jiji.com
reuters = https://jp.reuters.com/theWire
reuters_en = https://www.reuters.com/theWire
afpbb = https://www.afpbb.com
sankei = https://www.sankei.com/flash/newslist/flash-n1.html#6
bbc_japan = https://www.bbc.com/japanese
bbc = https://www.bbc.com/
#yahoo = https://news.yahoo.co.jp/
sputnik = https://jp.sputniknews.com/archive/
people = http://j.people.com.cn
#yna = https://jp.yna.co.kr/news
dailynk = https://dailynk.jp/archives/category/%e5%8c%97%e6%9c%9d%e9%ae%ae/%e3%83%93%e3%82%b8%e3%83%8d%e3%82%b9
guardian = https://www.theguardian.com/world/series/the-guardian-in-japanese

